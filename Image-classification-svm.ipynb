{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "704aefab",
   "metadata": {},
   "source": [
    "# Image Classification using Support Vector Machines (SVM)\n",
    "\n",
    "Welcome! My name is Yasin Pourraisi.  \n",
    "In this project, I will build a machine learning model to classify images of cats and dogs using the Support Vector Machines (SVM) algorithm. The goal is to explore how SVM and H.O.G. can be applied to computer vision tasks and evaluate its performance on distinguishing between cat and dog images.This model can also be trained to classify other types of images.\n",
    "\n",
    "**H.O.G. (Histogram of Oriented Gradients):**\n",
    "H.O.G. is a feature descriptor used in computer vision and image processing. It works by dividing an image into small regions (cells), calculating the gradient direction and magnitude for each pixel, and then creating a histogram of gradient directions for each cell. These histograms are combined to form a feature vector that describes the shape and appearance of objects in the image.\n",
    "\n",
    "**SVM (Support Vector Machine):**\n",
    "SVM is a supervised machine learning algorithm used for classification and regression tasks. It works by finding the optimal hyperplane that separates data points of different classes with the maximum margin. In image classification, SVM can be trained on feature vectors (like those from H.O.G.) to distinguish between categories.\n",
    "\n",
    "**Connect with me:**  \n",
    "- GitHub: [yasinpurraisi](https://github.com/yasinpurraisi)  \n",
    "- Email: yasinpurraisi@gmail.com  \n",
    "- Telegram: @yasinprsy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89528575",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "\n",
    "Let's start by importing all the necessary libraries for data processing, visualization, and building our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5e60b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca151485",
   "metadata": {},
   "source": [
    "### Load Images and Labels\n",
    "\n",
    "In this section, I load the image data and their corresponding labels from the dataset. The image file names and labels are stored in _annotation.json file, which you can [download here](https://cv-studio-accessible.s3.us-south.cloud-object-storage.appdomain.cloud/cats_dogs_images_.zip). For each image, I convert it to grayscale and resize it to 64 by 64 pixels to simplifies the algorithm and reduces computational requirements.\n",
    "and i append 0 for cat and 1 for dog to labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8aa821cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images =[]\n",
    "train_labels = []\n",
    "images_dir = \"cats_dogs_images/\" \n",
    "with open(\"cats_dogs_images/_annotations.json\",\"r\") as d:\n",
    "    data = json.load(d)\n",
    "    class_object = data['labels']\n",
    "    for key,value in data['annotations'].items():\n",
    "        image = cv2.imread(images_dir+key)\n",
    "        image = np.array(image).astype('uint8')\n",
    "        image = cv2.resize(image,(64,64))\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        hog_features, hog_images = hog(image,visualize=True,block_norm='L2-Hys',pixels_per_cell=(16, 16))\n",
    "        \n",
    "        label = 0 if value[0]['label'] == \"cat\" else 1\n",
    "        \n",
    "        train_images.append(hog_features)\n",
    "        train_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2046227",
   "metadata": {},
   "source": [
    "Create an array of the images and use the <code>np.vstack</code> to vertically stack arrays for wrangling,\n",
    "and i convert <code>train_labels</code> to a numpy array with <code>integers</code> and reshape <code>train_labels</code> to a 2D column vector\n",
    "\n",
    "finally i Concatenate the images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7fea0d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = np.array(train_images)\n",
    "train_array = np.vstack(train_array)\n",
    "labels_array = np.array(train_labels)\n",
    "labels_array = labels_array.astype(int)\n",
    "labels_array = labels_array.reshape((labels_array.size,1))\n",
    "#Concatenate\n",
    "train_df = np.concatenate([train_array, labels_array], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1998d73",
   "metadata": {},
   "source": [
    "### Split Data\n",
    "\n",
    "To evaluate the performance of my model, i split the dataset into two parts: a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8d3f2a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_df[:, :-1]\n",
    "y = train_df[:, -1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c0368",
   "metadata": {},
   "source": [
    "### Hyperparameters in SVM\n",
    "\n",
    "Hyperparameters are configuration settings used to control the behavior of a machine learning algorithm. In Support Vector Machines (SVM), the most important hyperparameters are:\n",
    "\n",
    "<ul>\n",
    "    <li><code>Kernel</code> Type:\n",
    "        <ul>\n",
    "            <li><code>Linear</code>: Used when data is linearly separable.</li>\n",
    "            <li><code>RBF</code> (Radial Basis Function): Good for non-linear problems; most widely used.</li>\n",
    "            <li><code>Poly</code> (Polynomial): Useful for data with polynomial relationships.</li>\n",
    "            <li><code>Sigmoid</code>: Similar to neural networksâ€™ activation function.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><code>C</code> (Regularization Parameter):\n",
    "        <ul>\n",
    "            Controls the trade-off between achieving a low error on the training data and maintaining a large margin for separation.\n",
    "            <li>High <code>C</code>: The model tries to classify all training examples correctly, possibly at the cost of a smaller margin (risk of overfitting).</li>\n",
    "            <li>Low <code>C</code>: The model allows more misclassifications but aims for a larger margin (better generalization, less overfitting).widely used.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "        <li><code>Gamma</code> for RBF Kernel:\n",
    "        <ul>\n",
    "            the spread of the kernel and, therefore, the decision region.\n",
    "            <li>High <code>Gamma</code>: The model only considers points very close to each other as similar (narrow decision region, risk of overfitting).</li>\n",
    "            <li>Low <code>Gamma</code>: The model considers points far away from each other as similar (wider decision region)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "i  select <code>C</code> : <code>[1, 10, 20, 30, 40]</code> and the best <code>kernel</code> : (Linear, RBF) by using the validation data.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ebf50368",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'kernel': ('linear', 'rbf'),'C': [1,10,20,30,40,100],'gamma': ['scale', 'auto', 0.01, 0.1, 1]}\n",
    "\n",
    "default_estimator = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dfd62a",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "i will train the model and try different kernels and parameter values using the function <code>GridSearchCV</code>. The resulting output will be the model that performs best on the validation data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "97e1118d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "svm = GridSearchCV(default_estimator, params, cv=5) # cv=5 : the training data is split into 5 parts\n",
    "svm.fit(x_train,y_train)\n",
    "best_parameters = svm.best_params_\n",
    "print(best_parameters)\n",
    "\n",
    "#predict labels for the test data\n",
    "y_pred = svm.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: \"+str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8175afc",
   "metadata": {},
   "source": [
    "now i save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8c0fae46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.joblib']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(svm.best_estimator_, 'svm_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26344019",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this project, I built an image classification model using Support Vector Machines (SVM) and Histogram of Oriented Gradients (H.O.G.) features to distinguish between cats and dogs. The workflow included loading and preprocessing images, extracting H.O.G. features, tuning SVM hyperparameters with GridSearchCV, and evaluating model performance. After training, the best model was saved for future use. While SVM with H.O.G. provides a solid baseline for image classification, further improvements can be achieved by optimizing feature extraction, scaling features, and experimenting with more advanced algorithms. This approach demonstrates the effectiveness of classical machine learning techniques in computer vision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
